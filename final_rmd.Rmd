---
title: "Final Report STA 141A"
author: "Tianyu Wang 917440012"
date: "2023-06-12"
output: html_document
---


## Abstract of the project
In this project of STA 141A at UC Davis, I analyze the data gather by Steinmetz et al. (2019) in their experiment of showing double monitors to mice and recording their reactions. The data contains 19 sessions of 4 mice, with more than a hundred trails of each session. In this report, I explore and explain the data structure, integrate the data frame, and build a predictive regression logistic model based on the the data frame I build.

## Introduction
The source of the data for this project is the experiment done by Steinmetz et al. at 2019 and their paper Distributed coding of choice, action and engagement across the mouse brain, published on Nature 576. Their expeirment aied to explore the key brain areas taking part in decision making of mammals.

Some of the key factors of the data set are:
contrast_left & contrast_right: the two panels will show the testing mice stimuli with contrast level in {0, 0.25, 0.5, 1}.
feedback_type: -1 or 1 only, depends on if the trail success (success = 1)
time: there are 40 time bins in total for the activity of each neuron cells for each trail
spks: number of responses each neuron cells show for specific time bin
brain_area: the location of each neuron cells live

Our goal of this project is to explore the structure of data set generated by this experiment, and try to build a predictive model of the feedback of the experiment based on the integrated data frame we build.
It's important to conduct this data analysis since it's key to facilitate to understand the logic of brains in making decisions.


## Part 1: Exploratory data analysis
This part of the project explore the data set and gives a brief summary and explanation of it

### 1.1: data structre
#### Data import: read the RDS files form the local ssd storage:
The 18 sessions of the entire data set are read and stored into an empty list in Rstudio. After import the data, I demonstrate the first 3 subject (i.e., 3 mice) as an illustration of the entire data set. I noticed that the though variables are same across all trails, the counts are different. The lengths (counts) of left contrast, right contrast, feedback type, spikes, and time are same since their count is the amount of trails conducted for each test subject. However, the counts are different between each subject, so I construct a new list called num_exp and stored the number of trails for each subject in it.

On the other hand, length of brain_area is the number of neurons tested for spikes (the interested result) for each test subject, and its length is also different for different subjects.

#### Data types of each variable:

##### contrast_left & contrast_right
numerical value in {0, 0.25, 0.5, 1}, demonstrating the strengthes of stimuli on left and right panel to the mice.

##### mouse_name
characters; the name of the mice

##### brain_area
list of characters, marking the area of each tested neuron

##### date_exp
a character of the date of the experiment

##### time
a list; the length of the list equals to the number of trails for each subject, and each sub-list contains 40 numerical values, which marking the centers of the time bins for spks

##### spks
also a list; the length of the list equals to the number of trails for each subject, but each sub-list contains all of the neurons (nubmer neuron = number brain area for each test subject) responses for 40 centers of the time bins.
```{r,warning=FALSE}

library(tidyverse) 
library(magrittr)   
library(knitr) 
library(dplyr) 

session=list()
for(i in 1:18){
  session[[i]]=readRDS(paste('D:/UC Davis/Spring 2023/STA 141/final/data/session',i,'.rds',sep=''))
}

summary(session[[1]])
summary(session[[2]])

num_exp = list()
for (i in 1:18){
  num_exp[i] = length(session[[i]]$contrast_left)
}
head(num_exp)
num_neuron = list()
for (i in 1:18){
  num_neuron[i] = length(session[[i]]$brain_area)
}
head(num_neuron)
```

This form sum up the basic information including # brain areas, # neuron cells, and success rate, categorized by the mice and experimental date.
```{r,warning=FALSE}
n.session=length(session)
meta <- tibble(
  mouse_name = rep('name',n.session),
  date_exp =rep('dt',n.session),
  n_brain_area = rep(0,n.session),
  n_neurons = rep(0,n.session),
  n_trials = rep(0,n.session),
  success_rate = rep(0,n.session)
)


for(i in 1:n.session){
  tmp = session[[i]];
  meta[i,1]=tmp$mouse_name;
  meta[i,2]=tmp$date_exp;
  meta[i,3]=length(unique(tmp$brain_area));
  meta[i,4]=dim(tmp$spks[[1]])[1];
  meta[i,5]=length(tmp$feedback_type);
  meta[i,6]=mean(tmp$feedback_type+1)/2;
}
kable(meta, format = "html", table.attr = "class='table table-striped'",digits=2) 
```


### 1.2
To look carefully of the neural activities of each trail, I take the first trail as an example. The num_neuron and num_exp tell me that there are 734 neuron cells from different brain areas and there are 114 trails for test subject (mouse Cori). This 114 corresponds to the lengths of spks data of session 1.There are 40 columns in spk1, which is same for all rest spks since there are 40 time bins. 

I demonstrate the first and the last matrix of the spikes result. The matrix has 734 rows, which corresponds to the number of neurons for this session. Each row represents one neuron, and a one indicates a spike in one of the 40 time bins.
```{r,warning=FALSE}
session[[1]]$mouse_name
num_neuron[1]
num_exp[1]
length(session[[1]]$spks)
```
Take another trail as an example:
```{r,warning=FALSE}
session_t=5
trail_t=1

spk.trial = session[[session_t]]$spks[[trail_t]]
area=session[[session_t]]$brain_area

spk.count=apply(spk.trial,1,sum)

tmp <- data.frame(
  area = area,
  spikes = spk.count
)

spk.average.dplyr =tmp %>%
  group_by(area) %>%
  summarize(mean= mean(spikes))
spk.average.dplyr
```
In the table above, we count the mean spikes of each brain area for session 5, trail 1. This formula could be later merged into a function and be applied in series to all of the sessions and trails.

```{r,warning=FALSE}
average_spike_area<-function(trail_t,this_session){
  spk.trial = this_session$spks[[trail_t]]
  area= this_session$brain_area
  spk.count=apply(spk.trial,1,sum)
  spk.average.tapply=tapply(spk.count, area, mean)
  return(spk.average.tapply)
  }

n.trial=length(session[[session_t]]$feedback_type)
n.area=length(unique(session[[session_t]]$brain_area ))

trial.summary =matrix(nrow=n.trial,ncol= n.area+1+2+1)
for(trail_t in 1:n.trial){
  trial.summary[trail_t,]=c(average_spike_area(trail_t,this_session = session[[session_t]]),
                          session[[session_t]]$feedback_type[trail_t],
                        session[[session_t]]$contrast_left[trail_t],
                        session[[session_t]]$contrast_right[session_t],
                        trail_t)
}

colnames(trial.summary)=c(names(average_spike_area(trail_t,this_session = session[[session_t]])), 'feedback', 'left contr.','right contr.','id' )

# Turning it into a data frame
trial.summary <- as_tibble(trial.summary)
trial.summary
```

### 1.3
After the mean stimulus calculation from the previous part, This plot describes the change of average of stimulus of each brain area among all trails in session 5. There are some decreasing trends based on the trend lines, but the real changing tendencies need to be studied further.
```{r,warning=FALSE}

area.col=rainbow(n=n.area,alpha=0.7)

plot(x=1,y=0, col='white',xlim=c(0,n.trial),ylim=c(0.5,2.2), xlab="Trials",ylab="Average spike counts", main=paste("Spikes per area in Session", session_t))


for(i in 1:n.area){
  lines(y=trial.summary[[i]],x=trial.summary$id,col=area.col[i],lty=2,lwd=1)
  lines(smooth.spline(trial.summary$id, trial.summary[[i]]),col=area.col[i],lwd=3)
  }
legend("topright", 
  legend = colnames(trial.summary)[1:n.area], 
  col = area.col, 
  lty = 1, 
  cex = 0.8
)
```

### 1.4
The graph below is the success rate vs. number of trails of each of the session plot. Each point on this graph represents one of the 18 test sessions. They are colored and connected by the mouse subject in order to compare across different session and mice. From the graph we can observe that the mouse Lederberg has a relatively higher success rate, especiall when the number of trails is small. However, this relativity needs more careful research to be assert.
```{r,warning=FALSE}
meta$mice_name <- as.factor(meta$mouse_name)
meta$suc_rate <- as.factor(meta$success_rate)
meta %>%
  ggplot(mapping = aes(x = n_trials, y= success_rate, group = mouse_name, color = mouse_name)) +
  geom_point(mapping = aes(color = mouse_name))+
  labs(x = 'Number of trails of each session', y = 'success rate of each session',title = 'Success rate vs. number of trails, across session and mice')+
  geom_line()
```

## Part 2: Data integration
In this data integration part, I used two for loops to go over each session, and then each trails in every session. I preserve the mean, sd of the spikes of each trail, the left/right values of trail, and the feedback of each trail. As a result, all of the 5081 trails from the 18 sessions are stroed in the single list, and this list is ready to train the model in future parts.
```{r,warning=FALSE}
sum_data <- list()

for (i in 1:18){
  session_cur = session[[i]]
  num_trail = length(session_cur$spks)
  for (j in 1:num_trail){
    session_num = i
    mean_spk = mean(session_cur$spks[[j]])
    sd_spk = sd(session_cur$spks[[j]])
    left_contrast = session_cur$contrast_left[[j]]
    right_contrast = session_cur$contrast_right[[j]]
    feedback = session_cur$feedback_type[[j]]
    mouse_name = session_cur$mouse_name
    sum_data <- rbind(sum_data, data.frame(
      session_num, mean_spk, sd_spk, left_contrast, right_contrast, feedback, mouse_name
    ))
  }
}
```

Then, a PCA could be applied on the data set in order to find the shared pattern while reducing the size of the data set.
```{r,warning=FALSE}
X = sum_data[, c('mean_spk', 'sd_spk', 'left_contrast', 'right_contrast')]
x_standardized <- scale(X)
pca_sum_data <- prcomp(x_standardized)
summary(pca_sum_data)
plot(pca_sum_data, type = "l", main = "Scree Plot")
biplot(pca_sum_data)
```

### Part 3: Model Training
```{r,warning=FALSE}
library(caret)
set.seed(11)

data_sum = list()

for(i in 1:length(session)) {
  feedback = session[[i]]$feedback_type
  num_spk = sapply(session[[i]]$spks, function(x) sum(rowSums(x)))
  left_contrast = session[[i]]$contrast_left
  right_contrast = session[[i]]$contrast_right
  

  data_sum[[i]] = data.frame(feedback, num_spk, left_contrast, right_contrast)
}

data_sum = do.call(rbind, data_sum)


data_sum$feedback = as.factor(data_sum$feedback)

train_indice = createDataPartition(data_sum$feedback, p = 0.85, list = FALSE)
train_set = data_sum[train_indice, ]
test_set = data_sum[-train_indice,]

glm_mod = train(feedback~., family = binomial, method = 'glm',data = train_set)
glm_mod
```

### Part 3: Model testing
To prepare the testing data for the glm_mod I build in the previsous section
```{r,warning=FALSE}
test_session = list()
for(i in 1:2){
  test_session[[i]]=readRDS(paste('D:/UC Davis/Spring 2023/STA 141/final/test_data/test',i,'.rds',sep=''))
}


test_data_1 <- list()
for(i in 1:1) {
  feedback = test_session[[i]]$feedback_type
  num_spk = sapply(test_session[[i]]$spks, function(x) sum(rowSums(x)))
  left_contrast = test_session[[i]]$contrast_left
  right_contrast = test_session[[i]]$contrast_right
  

  test_data_1[[i]] = data.frame(feedback, num_spk, left_contrast, right_contrast)
}

test_data_1 = do.call(rbind, test_data_1)


test_data_1$feedback = as.factor(test_data_1$feedback)



test_data_2 <- list()
for(i in 2:2) {
  feedback = test_session[[i]]$feedback_type
  num_spk = sapply(test_session[[i]]$spks, function(x) sum(rowSums(x)))
  left_contrast = test_session[[i]]$contrast_left
  right_contrast = test_session[[i]]$contrast_right
  

  test_data_2[[i]] = data.frame(feedback, num_spk, left_contrast, right_contrast)
}

test_data_2 = do.call(rbind, test_data_2)


test_data_2$feedback = as.factor(test_data_2$feedback)
```

To run the model based on the test data and find the confusion matrix
```{r,warning=FALSE}
prediction_test1 <- predict(glm_mod, newdata = test_data_1)
prediction_test1
prediction_test2 <- predict(glm_mod, newdata = test_data_2)

```

## Discussion
In the previous part, I integrated the data into a single data frame in order to analyze the data as a whole to build a precise predictive glm model of the feedback. However, when tested based on the test data provided, I found that all of the return predictive feed backs are 1. It's very unlikely to happen, so I need to acknowledge that there are some mistakes in my model. I carefully checked the train_set, and the set has feedback as categorical data with two levels '1' and '-1'; the train_set and two test_sets have the same dimension (i.e., number of rows). I have tried to change the seed I set in the program, but it still generate the same result.
Though my model did not successfully predict the result, I can provide 3 possible source errors:
1. the format of the train set might have some mistakes so the model is not correctly built
2. the testing data set have same format errors, so the model does not correctly read it
3. there are some mistakes in the way I build the glm model.

## Acknowledge:
1. ChatGPT: I used it to learn the dataset, some key concepts of the question of this final project, and build the outline of this project
2. Discussion materials: DIS 10 $ DIS 5 mainly
3. Lecture Notes
4. Steinmetz, N.A., Zatka-Haas, P., Carandini, M. et al. Distributed coding of choice, action and engagement across the mouse brain. Nature 576, 266–273 (2019). https://doi.org/10.1038/s41586-019-1787-x: I tried to read the original paper to understand the data set better.

## Entire codes used in the file
```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```

## Session information
```{r}
sessionInfo()
```